# tasks-ng dashboard with HTTPS via nginx reverse proxy
# Port 8082 serves HTTPS via Tailscale TLS

services:
  # Next.js application (internal only)
  app:
    build:
      context: .
      dockerfile: Dockerfile
    image: tasks-ng:local
    container_name: pai-tasks-ng-app
    user: "1000:1000"  # Run as host user to allow lock file creation

    environment:
      - NODE_ENV=production
      - PORT=3000
      - BACKLOG_PATH=/app/docs/BACKLOG.md
      - TASKS_FILE=/app/h3/tasks.md
      - DOCS_DIR=/app/docs
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-5-mini}
      - OPENAI_API_BASE_URL=${OPENAI_API_BASE_URL:-https://api.openai.com/v1}

    volumes:
      # Application data (persisted)
      - ./data:/app/data
      # Configuration
      - ./config:/app/config
      # Mount docs from project for progress page
      - /home/isecadmin/local/projects/tasks-ng/docs:/app/docs:ro
      # Mount h3 directory (actual location of tasks.md, allows lock files)
      - /home/isecadmin/local/h3:/app/h3:rw

    restart: unless-stopped

    networks:
      - tasks-ng-internal

    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # nginx reverse proxy with TLS termination
  nginx:
    image: nginx:alpine
    container_name: pai-tasks-ng
    depends_on:
      - app

    volumes:
      - ./nginx.conf:/etc/nginx/conf.d/default.conf:ro
      - ./certs:/etc/nginx/certs:ro

    ports:
      - "8082:443"

    restart: unless-stopped

    networks:
      - tasks-ng-internal
      - pai-internal

    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "--no-check-certificate", "https://localhost:443/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

networks:
  tasks-ng-internal:
    driver: bridge
  pai-internal:
    name: pai-internal
    external: true
